#
# Copyright 2014 Internet2
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

########################################
## Config chaining hierarchy
## Grouper loader uses Grouper Configuration Overlays (documented on wiki)
## By default the configuration is read from grouper-loader.base.properties
## (which should not be edited), and the grouper-loader.properties overlays
## the base settings.  See the grouper-loader.base.properties for the possible
## settings that can be applied to the grouper.properties
########################################

# comma separated config files that override each other (files on the right override the left)
# each should start with file: or classpath:
# e.g. classpath:grouper-loader.example.properties, file:c:/something/myconfig.properties
# {valueType: "string", required: true, multiple: true}
loader.config.hierarchy = classpath:grouper-loader.base.properties, classpath:grouper-loader.properties, database:grouper

# seconds between checking to see if the config files are updated
# {valueType: "integer", required: true}
loader.config.secondsBetweenUpdateChecks = 60

########################################
## General settings
########################################


# auto-add grouper loader types and attributes when grouper starts up if they are not there
# {valueType: "boolean", required: true}
loader.autoadd.typesAttributes = true

# if a transaction should be used when loading groups.  If not, then
# commits will happen as the group is loaded (and memory usage might be
# less intensive, and caching settings need to be set right)
# {valueType: "boolean", required: true}
loader.use.transactions = false

# if should use threads in the loader for add/remove member
# {valueType: "boolean", required: true}
loader.use.membershipThreads=true

# number of threads to use for each group job (not shared among jobs)
# {valueType: "integer", required: true}
loader.membershipThreadPoolSize=10

# if should use threads in the loader for each group in a group of groups
# {valueType: "boolean", required: true}
loader.use.groupThreads=true

# number of threads to use for each list of groups job (not shared among jobs)
# {valueType: "integer", required: true}
loader.groupThreadPoolSize=20

# if should use threads in incremental loader jobs
# {valueType: "boolean", required: true}
loader.incrementalThreads=true

# number of threads to use in incremental loader jobs (not shared among jobs)
# {valueType: "integer", required: true}
loader.incrementalThreadPoolSize=10

# number of days to retain db logs in table grouperloader_log.  -1 is forever.  default is 7
# {valueType: "integer", required: true}
loader.retain.db.logs.days=7

# number of days to retain db rows in grouper_change_log_entry.  -1 is forever.  default is 14
# {valueType: "integer", required: true}
loader.retain.db.change_log_entry.days=14

# if daemon should remove old values which are multi-assigned if the attribute is single valued
# {valueType: "boolean", required: true}
loader.removeMultiAttributeValuesIfSingleValuedAttribute = true

# if daemon should remove old values which are multi-assigned if the attribute is single valued
# {valueType: "boolean", required: true}
loader.removeMultiAttributeValuesIfSingleValuedAttributeLogOnly = true

# if daemon should remove old assignments which are multi-assigned if the attribute is single assign
# {valueType: "boolean", required: true}
loader.removeMultiAttributeAssignIfSingleAssignAttribute = true

# if daemon should remove old assignments which are multi-assigned if the attribute is single assign
# {valueType: "boolean", required: true}
loader.removeMultiAttributeAssignIfSingleAssignAttributeLogOnly = true


# if you want queries which do not specify subject source to come from a certain
# source, specify here (improves performance so it doesnt search through all sources)
# {valueType: "string"}
default.subject.source.id = 

#if using a sql table, and specifying the name like string, then should the group (in addition to memberships)
# be removed if not used anywhere else?
# {valueType: "boolean", required: true}
loader.sqlTable.likeString.removeGroupIfNotUsed = true

# if using a sql table, and specifying the name like string, then should the group be removed even when the group is member of some other group. 
# loader.sqlTable.likeString.removeGroupIfNotUsed has to be true for this to work
# https://bugs.internet2.edu/jira/browse/GRP-1132
# {valueType: "boolean", required: true}
loader.sqlTable.likeString.removeGroupIfMemberOfAnotherGroup = false

# by default the top folder for an ldap group of groups is the folder where the config group lives.
# set to false if you want to be able to provision groups to anywhere
# {valueType: "boolean", required: true}
loader.ldap.requireTopStemAsStemFromConfigGroup = true

# if you dont specify a groupNameExpression, groups will be loaded into this folder
# if this property doesnt exist, it will be groups:    if it is blank, then there is no top level folder
# e.g. loader:groups
# {valueType: "string"}
loader.ldap.defaultGroupFolder = groups:

# Delimiter used in the example edu.internet2.middleware.grouper.app.loader.ldap.LdapResultsTransformationDelimitedValueExample
# {valueType: "string"}
loader.ldap.resultsTransformationDelimitedValueExampleDelimiter = -

# Comma separated list of stems under which the display name changes in stems are allowed.
# eg: loader.allowStemDisplayNameChangesUnderStems=school:courses:english, school:faculty
# {valueType: "stem", multiple: true}
loader.allowStemDisplayNameChangesUnderStems =

# If a job creates or updates a group, and the job parameters do not compute
# a description, true if a blank description is allowed. If false, the description will
# be set to "{groupExtension} auto-created by grouperLoader".
# {valueType: "boolean", required: false}
loader.allowBlankGroupDescriptions = false

# fix include excludes on each run
# {valueType: "boolean", required: true}
loader.fixIncludeExcludes = false

#potentially delete groups that are no longer in the source system
# {valueType: "boolean", required: true}
loader.deleteGroupsNoLongerInSource = false

# if the db connections should be pooled (this is new as of 2.3.0.patch)
# {valueType: "boolean", required: true}
grouperLoader.db.connections.pool = true

############################################
## Auditing lifetimes
############################################

# number of days to retain db rows in grouper_audit_entry with no logged in user (loader, gsh, etc).  -1 is forever.  suggested is 365 or five years: 1825.  Default is -1
# audit entries with no logged in user aren't really all that useful.  There is point in time data still.  So removing these shouldn't be a big deal
# {valueType: "integer", required: true}
loader.retain.db.audit_entry_no_logged_in_user.days=-1

# number of days to retain db rows in grouper_audit_entry.  -1 is forever.  suggested is -1 or ten years: 3650
# Some think its ok to remove all audit entries over 10 (or X) years, but will default this 
# to never since even at large institutions there aren't that many records.  
# These are audits for things people do on the UI or WS generally (as a different to records with no logged in user) 
# {valueType: "integer", required: true}
loader.retain.db.audit_entry.days=-1

# number of days to retain db rows for point in time deleted objects.  -1 is forever.  suggested is 365 or five years: 1825.  Default is -1
# After you delete an object in grouper, it is still in point in time.  So if you want to know who 
# was in a group a year ago, you need this info
# However, after some time it might be ok to let it go.  So the default is 5 years
# {valueType: "integer", required: true}
loader.retain.db.point_in_time_deleted_objects.days=-1

# number of days after a subfolder (directly in a parent folder) is created that it will be obliterated (deleted) 
# and point in time will be deleted too. 
# "courses" or "anotherLabel" are variables you make up in these examples
# This is optional.  You can automatically obliterate folders *directly in a parent folder* that are a certain age old  e.g. courses.
# so you could delete a term of courses 4 years old if you like.  Note, make sure the loader isn't going to recreate or you will get churn
# Note this can also delete the point in time data as well.
# {valueType: "integer", required: true, regex: "^loader\\.retain\\.db\\.folder\\.([^.]+)\\.days$"}
#loader.retain.db.folder.courses.days=1825

# delete old folders in this folder
# {valueType: "stem", required: true, regex: "^loader\\.retain\\.db\\.folder\\.([^.]+)\\.parentFolderName$"}
#loader.retain.db.folder.courses.parentFolderName=my:folder:for:courses

# if also delete point in time for this old folder
# {valueType: "boolean", required: true, regex: "^loader\\.retain\\.db\\.folder\\.([^.]+)\\.deletePointInTime$"}
#loader.retain.db.folder.courses.deletePointInTime=true

# number of days after a subfolder (directly in a parent folder) is created that it will be obliterated (deleted) 
# and point in time will be deleted too. 
# "courses" or "anotherLabel" are variables you make up in these examples
# This is optional.  You can automatically obliterate folders *directly in a parent folder* that are a certain age old  e.g. courses.
# so you could delete a term of courses 4 years old if you like.  Note, make sure the loader isn't going to recreate or you will get churn
# Note this can also delete the point in time data as well.
# {valueType: "integer", required: true, regex: "^loader\\.retain\\.db\\.folder\\.([^.]+)\\.days$"}
#loader.retain.db.folder.anotherLabel.days=1825

# delete old folders in this folder
# {valueType: "stem", required: true, regex: "^loader\\.retain\\.db\\.folder\\.([^.]+)\\.parentFolderName$"}
#loader.retain.db.folder.anotherLabel.parentFolderName=my:folder:for:something

# if also delete point in time for this old folder
# {valueType: "boolean", required: true, regex: "^loader\\.retain\\.db\\.folder\\.([^.]+)\\.deletePointInTime$"}
#loader.retain.db.folder.anotherLabel.deletePointInTime=false



######################################
## Fail-safe 1 - Each individual group
######################################

# if the loader should check to see too many users were removed, if so, then error out and
# wait for manual intervention
# {valueType: "boolean", required: true}
loader.failsafe.use = false

# if a group has a size less than this (default 200), then make changes including blanking it out 
# {valueType: "integer", required: true}
loader.failsafe.minGroupSize = 200

# if a group with more members than the loader.failsafe.minGroupSize have more than this percent (default 30)  
# removed, then log it as error, fail the job, and don't actually remove the members 
# In order to run the job, an admin would need to change this param in the config, 
# and run the job manually, then change this config back 
# {valueType: "integer", required: true}
loader.failsafe.maxPercentRemove = 30


############################################
## Fail-safe 2 - Group list - managed groups
############################################

# For group lists, if groupLikeString is specified, you can use this fail-safe to prevent too
# many groups from having their memberships cleared out because they are managed by the loader
# (i.e. match the groupLikeString) but don't have memberships in the group query.
# {valueType: "boolean", required: true}
loader.failsafe.groupList.managedGroups.use = false

# Only applicable if the number of managed groups (i.e. match the groupLikeString) that have
# members in Grouper before the loader starts is at least this amount.
# {valueType: "integer", required: true}
loader.failsafe.groupList.managedGroups.minManagedGroups = 200

# If the group list meets the criteria above and the percentage of groups that are managed by
# the loader (i.e. match the groupLikeString) that currently have members in Grouper but 
# wouldn't after the job runs is greater than this percentage, then don't remove members,
# log it as an error and fail the job.  An admin would need to change this param in the config,
# and run the job manually, then change this config back.
# {valueType: "integer", required: true}
loader.failsafe.groupList.managedGroups.maxPercentRemove = 30


#################################
## Performance enhancements
#################################

# if you want to bulk retrieve subjects to add/remove
# {valueType: "boolean", required: true}
loader.bulkLookupSubjects = true

# If the bulk lookup should use lazy subjects to avoid actual subject lookups in the subject source.  This is mainly beneficial if your subject source includes an LDAP.
# {valueType: "boolean", required: true}
loader.bulkLookupSubjectsAsLazySubjects = true

#########################
## Unresolvables
#########################

# If there are unresolvables while loading a group from the source data, the job will still 
# have a result of SUCCESS unless the total membership count (with unresolvables) is 
# greater than or equal to minGroupSize and the percentage of unresolvables is greater than 
# the percent specified, in which case the result will be SUBJECT_PROBLEMS.
# {valueType: "integer", required: true}
loader.unresolvables.minGroupSize = 200

# If there are unresolvables while loading a group from the source data, the job will still 
# have a result of SUCCESS unless the total membership count (with unresolvables) is 
# greater than or equal to minGroupSize and the percentage of unresolvables is greater than 
# the percent specified, in which case the result will be SUBJECT_PROBLEMS.
# {valueType: "integer", required: true}
loader.unresolvables.maxPercentForSuccess = 5


#################################
## DB connections
## specify the db connection with user, pass, url, and driver class
## the string after "db." is the name of the connection, and it should not have
## spaces or other special chars in it
#################################

# specify the db connection with user, pass, url, and driver class
# the string after "db." is the name of the connection, and it should not have
# spaces or other special chars in it
# {valueType: "string", required: true, regex: "^db\\.([^.]+)\\.user$"}
# db.warehouse.user = mylogin

#note the password can be stored encrypted in an external file
# {valueType: "password", sensitive: true, regex: "^db\\.([^.]+)\\.pass$"}
#db.warehouse.pass = secret

# url for database connections
# {valueType: "string", required: true, regex: "^db\\.([^.]+)\\.url$"}
#db.warehouse.url = jdbc:mysql://localhost:3306/grouper

# note: you probably dont have to enter a driver, it will detect from URL.  If it
# cant detect, then specify it here
# {valueType: "string", required: true, regex: "^db\\.([^.]+)\\.driver$"}
#db.warehouse.driver = 

#optional pooling params, these will default to the grouper.hibernate(.base).properties pooling settings
# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.max_size$"}
#db.warehouse.c3p0.max_size = 100

# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.min_size$"}
#db.warehouse.c3p0.min_size = 0

# seconds
# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.timeout$"}
#db.warehouse.c3p0.timeout = 100

# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.max_statements$"}
#db.warehouse.c3p0.max_statements = 0

# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.idle_test_period$"}
#db.warehouse.c3p0.idle_test_period = 100

# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.acquire_increment$"}
#db.warehouse.c3p0.acquire_increment = 1

# {valueType: "boolean", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.validate$"}
#db.warehouse.c3p0.validate = false

# if unreturnedConnectionTimeout is non zero, then if connection takes too long it will be logged as stack
# {valueType: "boolean", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.debugUnreturnedConnectionStackTraces$"}
# db.warehouse.c3p0.debugUnreturnedConnectionStackTraces = false

# in seconds, if connections are removed from the pool for longer than this, 
# and debugUnreturnedConnectionStackTraces is true, then log the stack of who took the connection (and didnt return it)
# {valueType: "integer", required: true, regex: "^db\\.([^.]+)\\.c3p0\\.unreturnedConnectionTimeout$"}
# db.warehouse.c3p0.unreturnedConnectionTimeout = 30

#################################
## LDAP connections
## specify the ldap connection with user, pass, url
## the string after "ldap." is the ID of the connection, and it should not have
## spaces or other special chars in it.  In this case is it "personLdap"
#################################

# specify the ldap connection with user, pass, url
# the string after "ldap." is the ID of the connection, and it should not have
# spaces or other special chars in it.  In this case is it "personLdap"
#note the URL should start with ldap: or ldaps: if it is SSL.  
#It should contain the server and port (optional if not default), and baseDn, 
#e.g. ldaps://ldapserver.school.edu:636/dc=school,dc=edu
# {valueType: "string", required: true, regex: "^ldap\\.([^.]+)\\.url$"}
#ldap.personLdap.url = ldaps://ldapserver.school.edu:636/dc=school,dc=edu

# load this ldaptive config file before the configs here.  load from classpath
# {valueType: "string", required: true, regex: "^ldap\\.([^.]+)\\.configFileFromClasspath$"}
#ldap.personLdap.configFileFromClasspath = ldap.personLdap.properties

#optional, if authenticated
# {valueType: "string", required: true, regex: "^ldap\\.([^.]+)\\.user$"}
#ldap.personLdap.user = uid=someapp,ou=people,dc=myschool,dc=edu

#optional, if authenticated, note the password can be stored encrypted in an external file
# {valueType: "password", sensitive: true, regex: "^ldap\\.([^.]+)\\.pass$"}
#ldap.personLdap.pass = secret

#optional, if you are using tls, set this to true.  Generally you will not be using an SSL URL to use TLS...
# {valueType: "boolean", required: true, regex: "^ldap\\.([^.]+)\\.tls$"}
#ldap.personLdap.tls = false

#optional, if using sasl
# {valueType: "string", required: true, regex: "^ldap\\.([^.]+)\\.saslAuthorizationId$"}
#ldap.personLdap.saslAuthorizationId = 

#optional, if using sasl
# {valueType: "string", required: true, regex: "^ldap\\.([^.]+)\\.saslRealm$"}
#ldap.personLdap.saslRealm = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", required: true, regex: "^ldap\\.([^.]+)\\.batchSize$"}
#ldap.personLdap.batchSize = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", required: true, regex: "^ldap\\.([^.]+)\\.countLimit$"}
#ldap.personLdap.countLimit = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", required: true, regex: "^ldap\\.([^.]+)\\.timeLimit$"}
#ldap.personLdap.timeLimit = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", required: true, regex: "^ldap\\.([^.]+)\\.timeout$"}
#ldap.personLdap.timeout = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", required: true, regex: "^ldap\\.([^.]+)\\.minPoolSize$"}
#ldap.personLdap.minPoolSize = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", required: true, regex: "^ldap\\.([^.]+)\\.maxPoolSize$"}
#ldap.personLdap.maxPoolSize = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "boolean", required: true, regex: "^ldap\\.([^.]+)\\.validateOnCheckIn$"}
#ldap.personLdap.validateOnCheckIn = 

# validateOnCheckOut defaults to true if all other validate methods are false
# {valueType: "boolean", required: true, regex: "^ldap\\.([^.]+)\\.validateOnCheckOut$"}
#ldap.personLdap.validateOnCheckOut = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "boolean", regex: "^ldap\\.([^.]+)\\.validatePeriodically$"}
#ldap.personLdap.validatePeriodically = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", regex: "^ldap\\.([^.]+)\\.validateTimerPeriod$"}
#ldap.personLdap.validateTimerPeriod = 

#optional (note, time limit is for search operations, timeout is for connection timeouts), 
#most of these default to ldaptive defaults.  times are in millis
# {valueType: "integer", regex: "^ldap\\.([^.]+)\\.pruneTimerPeriod$"}
#ldap.personLdap.pruneTimerPeriod = 

# if there is a max size limit on ldap server, then this will retrieve results in pages
# {valueType: "integer", regex: "^ldap\\.([^.]+)\\.pagedResultsSize$"}
#ldap.personLdap.pagedResultsSize = 

# set to 'follow' if using AD and using paged results size and need this for some reason (generally you shouldnt)
# {valueType: "string", regex: "^ldap\\.([^.]+)\\.referral$"}
#ldap.personLdap.referral = 

# validator setup, currently supports CompareLdapValidator and SearchValidator.  additional properties below for CompareLdapValidator.
# {valueType: "string", regex: "^ldap\\.([^.]+)\\.validator$"}
#ldap.personLdap.validator = SearchValidator

# validator setup, currently supports CompareLdapValidator and SearchValidator.  additional properties below for CompareLdapValidator.
# {valueType: "string", regex: "^ldap\\.([^.]+)\\.validatorCompareDn$"}
#ldap.personLdap.validatorCompareDn = ou=people,dc=example,dc=com

# validator setup, currently supports CompareLdapValidator and SearchValidator.  additional properties below for CompareLdapValidator.
# {valueType: "string", regex: "^ldap\\.([^.]+)\\.validatorCompareAttribute$"}
#ldap.personLdap.validatorCompareAttribute = ou

# validator setup, currently supports CompareLdapValidator and SearchValidator.  additional properties below for CompareLdapValidator.
# {valueType: "string", regex: "^ldap\\.([^.]+)\\.validatorCompareValue$"}
#ldap.personLdap.validatorCompareValue = people

# comma-delimited list of classes to process LDAP search results. Useful if AD returns a ranged attribute for large
# groups (e.g., member;range=0-1499); include the GrouperRangeEntryHandler to handle progressive fetching.
# {valueType: "class", mustImplementInterface:"org.ldaptive.handler.Handler", multiple: true, regex: "^ldap\\.([^.]+)\\.searchResultHandlers$"}
#ldap.personLdap.searchResultHandlers=org.ldaptive.handler.DnAttributeEntryHandler,edu.internet2.middleware.grouper.ldap.ldaptive.GrouperRangeEntryHandler

# comma-delimited list of result codes (org.ldaptive.ResultCode) to ignore, e.g. TIME_LIMIT_EXCEEDED, SIZE_LIMIT_EXCEEDED, PARTIAL_RESULTS
# {valueType: "string", multiple: true, regex: "^ldap\\.([^.]+)\\.searchIgnoreResultCodes$"}
#ldap.personLdap.searchIgnoreResultCodes=SIZE_LIMIT_EXCEEDED

##################################
## LDAP loader settings
##################################

# el classes to add to the el context for the EL to calculate subejct ids or group names etc.  
# Comma-separated fully qualified classnamesm will be registered by the non-fully qualified
# uncapitalized classname.  So you register a.b.SomeClass, it will be available by variable: someClass
# {valueType: "class", multiple: true}
loader.ldap.el.classes = 

##################################
## Daemon logging
## When running the daemon log, do you want to log these various things?
##################################

# overall log for a job
# {valueType: "boolean", required: true}
daemon.log.logEnabled_overallLog = true

# subjob log for a job (e.g. if a job manages a lite of groups)
# {valueType: "boolean", required: true}
daemon.log.logEnabled_subjobLog = true

# groups being created or deleted
# {valueType: "boolean", required: true}
daemon.log.logEnabled_groupManagement = true

# memberships being created or deleted
# {valueType: "boolean", required: true}
daemon.log.logEnabled_membershipManagement = true

# if each logger map should have an id
# {valueType: "boolean", required: true}
daemon.log.logIdsEnabled = false



##################################
## Daily report
##################################
#quartz cron-like schedule for daily grouper report, the default is 7am every day: 0 0 7 * * ? 
#leave blank to disable this
# {valueType: "string"}
daily.report.quartz.cron = 

#comma separated email addresses to email the daily report, e.g. a@b.c, b@c.d
# {valueType: "string", multiple: true}
daily.report.emailTo = 

#days on which usdu should run with daily report (comma separated)
#blank means run never.   e.g. to run on all days: monday, tuesday, wednesday, thursday, friday, saturday, sunday
# {valueType: "string", multiple: true}
daily.report.usdu.daysToRun = monday, tuesday, wednesday, thursday, friday, saturday, sunday

#days on which bad membership finder should run with daily report (comma separated)
#blank means run never.   e.g. to run on all days: monday, tuesday, wednesday, thursday, friday, saturday, sunday
# {valueType: "string", multiple: true}
daily.report.badMembership.daysToRun = monday, tuesday, wednesday, thursday, friday, saturday, sunday

#if you put a directory here, the daily reports will be saved there, and you can
#link up to a web service or store them or whatever.  e.g. /home/grouper/reports/
# {valueType: "string"}
daily.report.saveInDirectory =

##################################
## enabled / disabled cron
##################################

#quartz cron-like schedule for enabled/disabled daemon.  Note, this has nothing to do with the changelog
#leave blank to disable this, the default is 12:01am, 11:01am, 3:01pm every day: 0 1 0,11,15 * * ? 
# {valueType: "string"}
changeLog.enabledDisabled.quartz.cron = 0 1 0,11,15 * * ?

##################################
## grouper builtin messaging cleanup cron
##################################

#quartz cron-like schedule for grouper messaging daemon.
#leave blank to disable this, the default is every hour, 10 minutes after the hour 
#this daemon does cleanup on the builtin messaging table
# {valueType: "string"}
changeLog.builtinMessagingDaemon.quartz.cron = 0 10 * * * ?

# after three days of not consuming messages, delete them, if -1, dont run this daemon
# {valueType: "integer", required: true}
grouper.builtin.messaging.deleteAllMessagesMoreThanHoursOld = 72

# after three hours of having processed messages, delete them.  Note, if this is -1 just delete when marking processed
# {valueType: "integer", required: true}
grouper.builtin.messaging.deleteProcessedMessagesMoreThanMinutesOld = 180





##################################
## Change log
##################################

# should the change log temp to change log daemon run?  Note, this should be true
# {valueType: "boolean", required: true}
changeLog.changeLogTempToChangeLog.enable = true

#quartz cron-like schedule for change log temp to change log daemon, the default is 50 seconds after every minute: 50 * * * * ?
# {valueType: "string"}
changeLog.changeLogTempToChangeLog.quartz.cron = 

# The max number of changes to send to a change log consumer at one time
# {valueType: "integer", required: true}
changeLog.changeLogConsumerBatchSize = 1000

# Should the change log include flattened memberships?  
# {valueType: "boolean", required: true}
changeLog.includeFlattenedMemberships = true

# Should the change log include flattened privileges?  
# {valueType: "boolean", required: true}
changeLog.includeFlattenedPrivileges = true

# Should the change log include roles that have had permission changes?  
# {valueType: "boolean", required: true}
changeLog.includeRolesWithPermissionChanges = false

# Should the change log include subjects that have had permission changes?
# {valueType: "boolean", required: true}
changeLog.includeSubjectsWithPermissionChanges = false

# Should the change log include non-flattened (immediate and composite only) memberships?
# {valueType: "boolean", required: true}
changeLog.includeNonFlattenedMemberships = false

# Should the change log include non-flattened (immediate only) privileges?
# {valueType: "boolean", required: true}
changeLog.includeNonFlattenedPrivileges = false

# Once the number of change log updates exceeds this value, the transaction will commit and a new one will be created
# {valueType: "integer", required: true}
changeLog.tooManyChangeLogUpdatesSize = 10000


##################################
## Change log consumers
##################################

# specify the consumers here.  specify the consumer name after the changeLog.consumer. part.  This example is "printTest"
# but it could be "myConsumerName" e.g. changeLog.consumer.myConsumerName.class
# the class must extend edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBase
# note see Impl below
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBase", regex: "^changeLog\\.consumer\\.([^.]+)\\.class$"}
# changeLog.consumer.printTest.class = edu.internet2.middleware.grouper.changeLog.consumer.PrintTest

# the quartz cron is a cron-like string.  it defaults to every minute on the minute (since the temp to change log job runs
# at 10 seconds to each minute).  it defaults to this: 0 * * * * ?
# though it will stagger each one by 2 seconds.  You can leave this blank
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.quartzCron$"}
# changeLog.consumer.printTest.quartzCron = 

# if you want to bump up the number of change log entries for a particular consumer, you can enter that here, per change log consumer
# {valueType: "integer"}
# changeLog.consumer.printTest.changeLogConsumerBatchSize = 1000

# rules consumer, needed for some of the Grouper rule types to run (e.g. flattenedMembershipRemove, flattenedMembershipAdd)
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBase"}
changeLog.consumer.grouperRules.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.RuleConsumer

# rules consumer, needed for some of the Grouper rule types to run (e.g. flattenedMembershipRemove, flattenedMembershipAdd)
# {valueType: "string"}
changeLog.consumer.grouperRules.quartzCron =

# consumer for syncing groups to other groupers
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBase"}
changeLog.consumer.syncGroups.class = edu.internet2.middleware.grouper.client.GroupSyncConsumer

# consumer for syncing groups to other groupers
# {valueType: "string"}
changeLog.consumer.syncGroups.quartzCron =


##################################
## Change log consumers based in Impl
## Note, you might want to extend: edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBaseImpl
## this is a higher level change log consumer that does a lot of logic for you
## this class will fire certain events for groups and memberships based on tagged folders or groups
## Note, to use this make an attribute and assign it to (generally) folder(s) or some groups or whatever
## GSH:
## GrouperSession grouperSession = GrouperSession.startRootSession();
## AttributeDef provisioningMarkerAttributeDef = new AttributeDefSave(grouperSession).assignCreateParentStemsIfNotExist(true).assignName("attr:someAttrDef").assignToStem(true).assignToGroup(true).save();
## AttributeDefName provisioningMarkerAttributeName = new AttributeDefNameSave(grouperSession, provisioningMarkerAttributeDef).assignName("attr:provisioningMarker").save()
## Stem parentFolder = StemFinder.findByName(grouperSession, "some:folder", true);
## parentFolder.getAttributeDelegate().assignAttribute(provisioningMarkerAttributeName);
##################################


# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBaseImpl", regex: "^changeLog\\.consumer\\.([^.]+)\\.class$"}
# changeLog.consumer.abc.class = edu.internet2.middleware.grouper.changeLog.consumer.PrintChangeLogConsumer

# note: this name matches the attribute name created in the example above
# {valueType: "attributeDefName", regex: "^changeLog\\.consumer\\.([^.]+)\\.syncAttributeName$"}
# changeLog.consumer.abc.syncAttributeName = attr:provisioningMarker

# quartz cron of consumer
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.quartzCron$"}
# changeLog.consumer.abc.quartzCron =

# defaults to true if not configured
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.retryOnError$"}
# changeLog.consumer.abc.retryOnError = true


##################################
## PSPNG
##################################


# All Provisioners: provisioner class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.pspng.PspChangelogConsumerShim", regex: "^changeLog\\.consumer\\.([^.]+)\\.class$"}
# changeLog.consumer.myPspng.class = edu.internet2.middleware.grouper.pspng.PspChangelogConsumerShim

# Whether the provisioner will make changes. When this is false, the provisioner skips all changelog or full-sync requests. 
# The provisioner reflects changes in Grouper downstream to the target system.
# {valueType: "boolean", defaultValue: "true", regex: "^changeLog\\.consumer\\.([^.]+)\\.enabled$"}
# changeLog.consumer.myPspng.enabled = true

# Jexl expression that refers to stem_attributes, group_attributes, or group  Provision groups if <provisionerName> is in 
# a group or stem provision_to attribute AND NOT in a do_not_provision_to attribute
# {valueType: "String", regex: "^changeLog\\.consumer\\.([^.]+)\\.groupSelectionExpression$"}
# changeLog.consumer.myPspng.groupSelectionExpression = ${ utils.containedWithin(provisionerName, stemAttributes['etc:pspng:provision_to'], groupAttributes['etc:pspng:provision_to']) && !utils.containedWithin(provisionerName, stemAttributes['etc:pspng:do_not_provision_to'], groupAttributes['etc:pspng:do_not_provision_to']) }

# List of Grouper Attributes used in group selection. Used to improve the speed of finding relevant groups. Use the groupSelectionExpression 
# against groups either with provision_to/do_not_provision_to Attributes or in folders with those attributes.
# {valueType: "String", regex: "^changeLog\\.consumer\\.([^.]+)\\.attributesUsedInGroupSelectionExpression$"}
# changeLog.consumer.myPspng.attributesUsedInGroupSelectionExpression = etc:pspng:provision_to, etc:pspng_do_not_provision_to

# True: the values of the attributes listed in attributesUsedInGroupSelectionExpression are the provisioner names.
# False: The attributes listed in attributesUsedInGroupSelectionExpression have different values than the provisioner
# PSPNG does a database search for Attribute=<provisioner name> which narrows the number of groups to compare to the groupSelectionExpression.
# {valueType: "String", regex: "^changeLog\\.consumer\\.([^.]+)\\.attributesUsedInGroupSelectionExpressionAreComparedToProvisionerName$"}
# changeLog.consumer.myPspng.attributesUsedInGroupSelectionExpressionAreComparedToProvisionerName = true

# How long should Grouper (Group, Stem, Subject) data be cached by the provisioners?  Grouper data will be cached for 10 minutes, 
# though it is flushed when groups change.
# {valueType: "Integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.grouperDataCacheTime_secs$"}
# changeLog.consumer.myPspng.grouperDataCacheTime_secs = 600

# How many Grouper Groups should be kept in memory at a time? 
# {valueType: "Integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.grouperGroupCacheSize$"}
# changeLog.consumer.myPspng.grouperGroupCacheSize = 10000

# How many Grouper Subjects should be kept in memory at a time? 
# {valueType: "Integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.grouperSubjectCacheSize$"}
# changeLog.consumer.myPspng.grouperSubjectCacheSize = 10000

# Does provisioniner need User/Subject information from the Target System? For example, do any JEXL expressions need 
# information that is not available in Grouper Subjects? All provisioning will be done based (only) on Grouper-Subject information.
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.needsTargetSystemUsers$"}
# changeLog.consumer.myPspng.needsTargetSystemUsers = false

# Does provisioner need group information from the Target System? For example, this information could be used in various 
# JEXL expressions.  All provisioning will need to be done based on Grouper-Group information
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.needsTargetSystemGroups$"}
# changeLog.consumer.myPspng.needsTargetSystemGroups = false

# Only used when needsTargetSystemUsers=true: Should users be created when they cannot be found?  Users will not be created by 
# Grouper Provisioning. Provisioning actions that require the users will fail.
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.createMissingUsers$"}
# changeLog.consumer.myPspng.createMissingUsers = false

# Only used when needsTargetSystemUsers=true: How many users can be sought in a single Fetch? Fetches 
# will seek information for up to 50 users at a single time.
# {valueType: "integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.userSearch_batchSize$"}
# changeLog.consumer.myPspng.userSearch_batchSize = 50

# Only used when needsTargetSystemGroups=true: How many groups can be sought in a single Fetch? 
# Fetches will seek information for up to 50 groups at a time.
# {valueType: "integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.groupSearch_batchSize$"}
# changeLog.consumer.myPspng.groupSearch_batchSize = 50

# Can groups be created without any members? If so, it is easier to create them separately 
# from membership changes. Yes, create groups as soon as possible.
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.supportsEmptyGroups$"}
# changeLog.consumer.myPspng.supportsEmptyGroups = true

# FullSync: Wait a bit before retrying a group that has failed. This prevents aggressive infinite 
# loops.  1 second pause before retrying a failed group.
# {valueType: "integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.sleepTimeAfterError_ms$"}
# changeLog.consumer.myPspng.sleepTimeAfterError_ms = 1000

# LdapProvisioner: What ldap pool should be used by this provisioner 
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.ldapPoolName$"}
# changeLog.consumer.myPspng.ldapPoolName = myLdapConnection

# Where to find users?  Required if provisioner needsTargetSystemUsers=true
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.userSearchBaseDn$"}
# changeLog.consumer.myPspng.userSearchBaseDn = 

# Jexl expression that refers to stem_attributes, group_attributes, or group  How to find users in the Target System?
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.userSearchFilter$"}
# changeLog.consumer.myPspng.userSearchFilter = 

# Comma-separated list of attributes that are useful for logging and that are needed by userSearchFilter or by a subclass's ValueFormats  
# Reads common attributes from either Unix or ActiveDirectory LDAP servers
# {valueType: "string", multiple: true, regex: "^changeLog\\.consumer\\.([^.]+)\\.ldapPoolName$"}
# changeLog.consumer.myPspng.userSearchAttributes = dn,cn,uid,mail,samAccountName,uidNumber,objectclass

# Whether paging should be enabled in LDAP search requests; This typically requires the paging extension to be 
# enabled and configured in LDAP to avoid LDAP Error Code 12. 
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.searchResultPagingEnabled$"}
# changeLog.consumer.myPspng.searchResultPagingEnabled = true

# How many result objects can be pulled by a single request. This is small to avoid problems by default.  Break the results 
# of a large query into fairly tiny chunks. 
# {valueType: "integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.ldapSearchResultPagingSize$"}
# changeLog.consumer.myPspng.ldapSearchResultPagingSize = 100

# How long to keep User information in memory?  Keep User information in memory for 10 minutes, though user-information 
# is flushed when users are changed by a provisioner
# {valueType: "integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.ldapUserCacheTime_secs$"}
# changeLog.consumer.myPspng.ldapUserCacheTime_secs = 600

# Deprecated: use the more general targetSystemUserCacheSize.  How many LDAP accounts can be kept in memory at a time, indexed by the 
# Subject mapped to them?  Keep the last 10000 users found by searching with Subject information
# {valueType: "integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.ldapUserCacheSize$"}
# changeLog.consumer.myPspng.ldapUserCacheSize = 10000

# Is this an active-directory server? If so, then AD-specific attribute-value-paging is enabled. Also, member (reverse user-to-group 
# virtual attribute) is enabled. LDAP server is treated like a non-active-directory server. Problems will occur with full-sync of large groups.
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.isActiveDirectory$"}
# changeLog.consumer.myPspng.isActiveDirectory = false

# How many values can be added/removed from an attribute in a single ldap operation Breaks large list of values that need to be added/removed 
# from an attribute into chunks that this size. For example, 5000 values that need to be added would be added in 50 chunks of 100 values each.
# {valueType: "integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.maxValuesToChangePerOperation$"}
# changeLog.consumer.myPspng.maxValuesToChangePerOperation = 100

# Target system cache size
# {valueType: "integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.maxValuesToChangePerOperation$"}
# changeLog.consumer.myPspng.targetSystemUserCacheSize = 10000

# User creation base dn.  Warning: Grouper PSPNG is not a good provisioner for Accounts/Subjects. See 'Account Creation' section below.
# Where should account-/subject-objects be created when they don't already exist?
# This is only used if createMissingUsers=true
# This is appended to the dn attribute produced by the userCreationLdifTemplate.
# {valueType: "String", regex: "^changeLog\\.consumer\\.([^.]+)\\.userCreationBaseDn$"}
# changeLog.consumer.myPspng.userCreationBaseDn = 

# Warning: Grouper PSPNG is not a good provisioner for Accounts/Subjects. See 'Account Creation' section below.
# What account/subject ldap objects should be created when they don't already exist in the LDAP directory?
# This is only used if createMissingUsers=true
# {valueType: "String", regex: "^changeLog\\.consumer\\.([^.]+)\\.userCreationLdifTemplate$"}
# changeLog.consumer.myPspng.userCreationLdifTemplate = 

# 'member' for AD <required> otherwise
# What attribute represents a group's members in the Target System? Active Directory should just work. Otherwise, this is required.
# {valueType: "String", regex: "^changeLog\\.consumer\\.([^.]+)\\.memberAttributeName$"}
# changeLog.consumer.myPspng.memberAttributeName = 

# ${ldapUser.dn} What value (typically based on Subject or TargetSystemUser information) is written into the 
# memberAttributeName attribute of groups?  Active Directory and GroupOfUniqueNames will typically work. This 
# is a JEXL expression and is parsed at runtime. You may choose to script your way into this, by perhaps choosing a specific attribute:
# ${ldapUser.getStringValue("uid")}
# {valueType: "String", regex: "^changeLog\\.consumer\\.([^.]+)\\.memberAttributeValueFormat$"}
# changeLog.consumer.myPspng.memberAttributeValueFormat = 

# memberof for AD, null otherwise, Virtual attribute of accounts that lists their groups 
# {valueType: "String", regex: "^changeLog\\.consumer\\.([^.]+)\\.groupAttributeName$"}
# changeLog.consumer.myPspng.groupAttributeName = 

# What LDIF should be written to the directory to add a group. Multiple lines need to be separated by || (double-pipes). 
# The DN of the LDIF will be combined with groupCreationBaseDn>  
# For AD, limit to less than 1024 if sending description, like this:
# description: ${org.apache.commons.lang3.StringUtils.abbreviate(group.description == null ? null : group.description.replaceAll("\\r\\n"," ").replaceAll("\\n"," ").replaceAll("\\r"," "), 900)}
# {valueType: "String", regex: "^changeLog\\.consumer\\.([^.]+)\\.groupCreationLdifTemplate$"}
# changeLog.consumer.myPspng.groupCreationLdifTemplate = 

# Where should groups be created? At group-creation time, this is appended to the DN that results from the 
# groupCreationLdifTemplate. Groups are created starting at the top of the search BaseDn.
# {valueType: "String", regex: "^changeLog\\.consumer\\.([^.]+)\\.groupCreationBaseDn$"}
# changeLog.consumer.myPspng.groupCreationBaseDn = 

# Where are groups found? 
# {valueType: "String", regex: "^changeLog\\.consumer\\.([^.]+)\\.groupSearchBaseDn$"}
# changeLog.consumer.myPspng.groupSearchBaseDn = 

# If set to TRUE, groups under groupCreationBaseDn that are not in Grouper will be removed at the end of a full sync. During 
# full syncs, groups are not removed if they do not match the allGroupsSearchFilter or groupSelectionExpression. 
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.grouperIsAuthoritative$"}
# changeLog.consumer.myPspng.grouperIsAuthoritative = false

# FUTURE: How to find all the groups that grouper-provisioning maintains. If <grouperIsAuthoritative>, then groups found 
# via this filter will be removed during a full sync.  Groups are not removed when they are removed from Grouper nor when 
# they no longer match the groupSelectionExpression.
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.allGroupsSearchFilter$"}
# changeLog.consumer.myPspng.allGroupsSearchFilter = 

# How to find a group, based on Grouper Group (or stem) information 
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.singleGroupSearchFilter$"}
# changeLog.consumer.myPspng.singleGroupSearchFilter = 

# cn,gidNumber,samAccountName,objectclass
# Attributes that should be read from groups when searching for them. This needs to include all the attributes used in 
# singleGroupSearchFilter. This should not include the attribute which holds the group's members.  Support common, 
# basic singleGroupSearchFilters.
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.groupSearchAttributes$"}
# changeLog.consumer.myPspng.groupSearchAttributes = 

# How long should LDAP-Group information be cached in memory? Keep LDAP Group information in memory for 10 minutes, 
# though it is flushed when users are changed by a provisioner.
# {valueType: "integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.ldapGroupCacheTime_secs$"}
# changeLog.consumer.myPspng.ldapGroupCacheTime_secs = 600

# How many LDAP groups to keep in memory, indexed by Grouper Group. 
# {valueType: "integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.ldapGroupCacheSize$"}
# changeLog.consumer.myPspng.ldapGroupCacheSize = 10000

# See above (JEXL expressions use User and Group information from the Target System)  
# {valueType: "integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.needsTargetSystemUsers$"}
# changeLog.consumer.myPspng.needsTargetSystemUsers = true

# See above (JEXL expressions use User and Group information from the Target System).  LdapAttributeProvisioner
# (Also Provisioner and LDAPProvisioner)  
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.needsTargetSystemGroups$"}
# changeLog.consumer.myPspng.needsTargetSystemGroups = true

# What attribute is changed in User LDAP objects to represent group membership? 
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.provisionedAttributeName$"}
# changeLog.consumer.myPspng.provisionedAttributeName = true

# What value (typically based on Subject or TargetSystemUser information) is written into the provisionedAttributeName users? 
# The stem:Group name is written to the attribute specified in <provisionedAttributeName>
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.provisionedAttributeValueFormat$"}
# changeLog.consumer.myPspng.provisionedAttributeValueFormat = ${group.name}

# See above (JEXL expressions only use User information from the Target System) 
# {valueType: "integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.needsTargetSystemUsers$"}
# changeLog.consumer.myPspng.needsTargetSystemUsers = true

# See above (JEXL expressions only use User information from the Target System) 
# {valueType: "integer", regex: "^changeLog\\.consumer\\.([^.]+)\\.needsTargetSystemGroups$"}
# changeLog.consumer.myPspng.needsTargetSystemGroups = false

# What values of the attribute is grouper authoritative for during a full sync? null (default) or empty means 
# that pspng will only process removals as memberships change, and won't clean up unknown attribute values. Warning: 
# Grouper should have full control over the target attribute to avoid complications that come from sharing attributes with multiple provisioning tools.
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.allProvisionedValuesPrefix$"}
# changeLog.consumer.myPspng.allProvisionedValuesPrefix =


##################################
## PSP
##################################

# psp consumer class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.psp.grouper.PspChangeLogConsumer"}
# changeLog.consumer.psp.class = edu.internet2.middleware.psp.grouper.PspChangeLogConsumer

# http://www.quartz-scheduler.org/documentation/quartz-1.x/tutorials/crontrigger
# {valueType: "string"}
# changeLog.consumer.psp.quartzCron = 0 * * * * ?

# To retry processing a change log entry if an error occurs, set retryOnError to true. Defaults to false.
# {valueType: "boolean", required: true}
# changeLog.consumer.psp.retryOnError = false

# To run full provisioning synchronizations periodically, provide the class name which provides a 'public void fullSync()' method.
# {valueType: "class"}
# changeLog.psp.fullSync.class = edu.internet2.middleware.psp.grouper.PspChangeLogConsumer

# Schedule full synchronizations. Defaults to 5 am : 0 0 5 * * ?.
# {valueType: "string"}
# changeLog.psp.fullSync.quartzCron = 0 0 5 * * ?

# Run a full synchronization job at startup. Defaults to false.
# {valueType: "boolean", required: true}
# changeLog.psp.fullSync.runAtStartup = false

# Omit diff responses from bulk response to conserve memory.
# {valueType: "boolean", required: true}
# changeLog.psp.fullSync.omitDiffResponses = true

# Omit sync responses from bulk response to conserve memory.
# {valueType: "boolean", required: true}
# changeLog.psp.fullSync.omitSyncResponses = true




###################################
## XMPP notifications 
## (note, uncomment the consumer class and cron above)
## this will get grouper ws getMembers rest lite xmp: 
## http://anonsvn.internet2.edu/cgi-bin/viewvc.cgi/i2mi/trunk/grouper-ws/grouper-ws/doc/samples/getMembers/WsSampleGetMembersRestLite_xml.txt?view=log
###################################

# general xmpp configuration
# {valueType: "string"}
xmpp.server.host = jabber.school.edu

# xmpp port
# {valueType: "integer", required: true}
xmpp.server.port = 5222

# xmpp username
# {valueType: "string"}
xmpp.user = username

# note, pass can be in an external file with morphstring
# {valueType: "password", sensitive: true}
xmpp.pass = 

# xmpp resource
# {valueType: "string"}
xmpp.resource = grouperServer

###################################
## Rules config
###################################

# when the rules validations and daemons run.  Leave blank to not run
# {valueType: "string"}
rules.quartz.cron = 0 0 7 * * ?

#####################################
## Messaging overall settings for daemon jobs
#####################################

# auto create built in queues, topics, privileges
# {valueType: "boolean", required: true}
loader.messaging.settings.autocreate.objects = true


#####################################
## Messaging listener using the messaging API
## note, change "messagingListener" in key to be the name of the listener.  e.g. messaging.listener.myAzureListener.class
## extends edu.internet2.middleware.grouper.messaging.MessagingListenerBase
## note, routingKey property is valid only for rabbitmq. For other messaging systems, it is ignored.
## this listener will just print out messages: edu.internet2.middleware.grouper.messaging.MessagingListenerPrint
#####################################

# messaging listener class
# {valueType: "class", required: true, mustExtendClass: "edu.internet2.middleware.grouper.messaging.MessagingListener", regex: "^messaging\\.listener\\.([^.]+)\\.class$"}
#messaging.listener.messagingListener.class = edu.internet2.middleware.grouper.messaging.MessagingListener

# messaging listener quartz cron
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.quartzCron$"}
#messaging.listener.messagingListener.quartzCron = 0 * * * * ?

# messaging listener messaging system name
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.messagingSystemName$"}
#messaging.listener.messagingListener.messagingSystemName = grouperBuiltinMessaging

# messaging listener queue name
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.queueName$"}
#messaging.listener.messagingListener.queueName = abc

# messaging listener routing key
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.routingKey$"}
#messaging.listener.messagingListener.routingKey =

# messaging listener exchange type. Valid options are DIRECT, HEADERS, TOPIC, FANOUT
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.exchangeType$"}
#messaging.listener.messagingListener.exchangeType =

# messaging listener number of tries per iteration
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.numberOfTriesPerIteration$"}
#messaging.listener.messagingListener.numberOfTriesPerIteration = 3

# messaging listener polling timeout seconds
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.pollingTimeoutSeconds$"}
#messaging.listener.messagingListener.pollingTimeoutSeconds = 18

# messaging listener sleep seconds in between iterations
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.sleepSecondsInBetweenIterations$"}
#messaging.listener.messagingListener.sleepSecondsInBetweenIterations = 0

# messaging listener max messages to receive at once
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.maxMessagesToReceiveAtOnce$"}
#messaging.listener.messagingListener.maxMessagesToReceiveAtOnce = 20

# if there are 20 messages to receive at once, then do this 50 times per call max
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.maxOuterLoops$"}
#messaging.listener.messagingListener.maxOuterLoops = 50

#####################################
## Messaging listener using the change log consumer API
#####################################

# note, change "messagingListenerChangeLogConsumer" in key to be the name of the listener.  e.g. messaging.listener.myAzureListener.class
# keep this class to be MessagingListenerToChangeLogConsumer
# {valueType: "class", required: true, mustExtendClass: "edu.internet2.middleware.grouper.messaging.MessagingListenerToChangeLogConsumer", regex: "^messaging\\.listener\\.([^.]+)\\.class$"}
#messaging.listener.messagingListenerChangeLogConsumer.class = edu.internet2.middleware.grouper.messaging.MessagingListenerToChangeLogConsumer

# Class extends: edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBase
# {valueType: "class", required: true, mustExtendClass: "edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerBase", regex: "^messaging\\.listener\\.([^.]+)\\.changeLogConsumerClass$"}
#messaging.listener.messagingListenerChangeLogConsumer.changeLogConsumerClass = edu.internet2.middleware.grouper.messaging.SomethingExtendsChangeLogConsumerBase

# messaging listener quartz cron
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.quartzCron$"}
#messaging.listener.messagingListenerChangeLogConsumer.quartzCron = 0 * * * * ?

# system name
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.messagingSystemName$"}
#messaging.listener.messagingListenerChangeLogConsumer.messagingSystemName = grouperBuiltinMessaging

# queue name in messaging system
# {valueType: "string", regex: "^messaging\\.listener\\.([^.]+)\\.queueName$"}
#messaging.listener.messagingListenerChangeLogConsumer.queueName = abc

# number of tries per iteration
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.numberOfTriesPerIteration$"}
#messaging.listener.messagingListenerChangeLogConsumer.numberOfTriesPerIteration = 3

# polling timeout seconds
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.pollingTimeoutSeconds$"}
#messaging.listener.messagingListenerChangeLogConsumer.pollingTimeoutSeconds = 18

# sleep seconds in between iteration
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.sleepSecondsInBetweenIterations$"}
#messaging.listener.messagingListenerChangeLogConsumer.sleepSecondsInBetweenIterations = 0

# max messages to receive at once
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.maxMessagesToReceiveAtOnce$"}
#messaging.listener.messagingListenerChangeLogConsumer.maxMessagesToReceiveAtOnce = 20

# max outer loops
# if there are 20 messages to receive at once, then do this 50 times per call max
# {valueType: "integer", regex: "^messaging\\.listener\\.([^.]+)\\.maxOuterLoops$"}
#messaging.listener.messagingListenerChangeLogConsumer.maxOuterLoops = 50


#####################################
## Messaging integration with change log, send change log entries to a messaging system
#####################################

# note, change "messaging" in key to be the name of the consumer.  e.g. changeLog.consumer.myAzureConsumer.class
# note, routingKey property is valid only for rabbitmq. For other messaging systems, it is ignored.
# {valueType: "class", required: true, mustExtendClass: "edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerToMessage", regex: "^changeLog\\.consumer\\.([^.]+)\\.class$"}
#changeLog.consumer.messaging.class = edu.internet2.middleware.grouper.changeLog.ChangeLogConsumerToMessage

# quartz cron
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.quartzCron$"}
#changeLog.consumer.messaging.quartzCron = 0 * * * * ?

# system name
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.messagingSystemName$"}
#changeLog.consumer.messaging.messagingSystemName = grouperBuiltinMessaging

# routing key
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.routingKey$"}
#changeLog.consumer.messaging.routingKey = 

# exchange type. valid options are DIRECT, TOPIC, HEADERS, FANOUT
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.exchangeType$"}
#changeLog.consumer.messaging.exchangeType = 

# queue or topic
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.messageQueueType$"}
#changeLog.consumer.messaging.messageQueueType = queue

# queue or topic name
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.queueOrTopicName$"}
#changeLog.consumer.messaging.queueOrTopicName = abc


#####################################
## Messaging integration with ESB, send change log entries to a messaging system
#####################################

# note, change "messagingEsb" in key to be the name of the consumer.  e.g. changeLog.consumer.myAzureConsumer.class
# note, routingKey property is valid only for rabbitmq. For other messaging systems, it is ignored.
#changeLog.consumer.messagingEsb.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbConsumer

# quartz cron
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.quartzCron$"}
#changeLog.consumer.messagingEsb.quartzCron = 0 * * * * ?

# el filter
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.elfilter$"}
#changeLog.consumer.messagingEsb.elfilter = event.eventType eq 'GROUP_DELETE' || event.eventType eq 'GROUP_ADD' || event.eventType eq 'MEMBERSHIP_DELETE' || event.eventType eq 'MEMBERSHIP_ADD'

# publishing class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbMessagingPublisher", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.class$"}
#changeLog.consumer.messagingEsb.publisher.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbMessagingPublisher

# messaging system name
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.messagingSystemName$"}
#changeLog.consumer.messagingEsb.publisher.messagingSystemName = grouperBuiltinMessaging

# routing key
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.routingKey$"}
#changeLog.consumer.messagingEsb.publisher.routingKey = 

# EL replacement definition. groupName is the variable for the name of the group. grouperUtil is the class GrouperUtilElSafe can be used for utility methods. 
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.regexRoutingKeyReplacementDefinition$"}
#changeLog.consumer.messagingEsb.regexRoutingKeyReplacementDefinition = ${groupName.replaceFirst('hawaii.edu', 'group.modify').replace(':enrolled', '').replace(':waitlisted', '').replace(':withdrawn', '')}

# replace routing key with periods
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.replaceRoutingKeyColonsWithPeriods$"}
#changeLog.consumer.messagingEsb.replaceRoutingKeyColonsWithPeriods = true

# queue or topic
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.messageQueueType$"}
#changeLog.consumer.messagingEsb.publisher.messageQueueType = queue

# queue or topic name
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.queueOrTopicName$"}
#changeLog.consumer.messagingEsb.publisher.queueOrTopicName = abc

# exchange type for rabbitmq. valid options are DIRECT, TOPIC, HEADERS, FANOUT
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.exchangeType$"}
#changeLog.consumer.messagingEsb.publisher.exchangeType = 

#####################################
## ESB integration
#####################################

# quartz cron
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.quartzCron$"}
#changeLog.consumer.awsJira.quartzCron = 0/15 * * * * ?

# class
# {valueType: "class", required: true, mustExtendClass: "edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbConsumer", regex: "^changeLog\\.consumer\\.([^.]+)\\.class$"}
#changeLog.consumer.awsJira.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbConsumer

# el filter
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.elfilter$"}
#changeLog.consumer.awsJira.elfilter = event.eventType eq 'MEMBERSHIP_ADD' || event.eventType eq 'MEMBERSHIP_ADD'

# if dont send sensitive data
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.noSensitiveData$"}
#changeLog.consumer.awsJira.noSensitiveData = true

# if you want to encrypt messages, set this to an implementation of edu.internet2.middleware.grouperClient.encryption.GcEncryptionInterface
# {valueType: "class", regex: "^changeLog\\.consumer\\.([^.]+)\\.encryptionImplementation$", mustImplementInterface: "edu.internet2.middleware.grouperClient.encryption.GcEncryptionInterface"}
#changeLog.consumer.awsJira.encryptionImplementation = edu.internet2.middleware.grouperClient.encryption.GcSymmetricEncryptAesCbcPkcs5Padding

# this is a key or could be encrypted in a file as well like other passwords
# generate a key with: java -cp grouperClient.jar edu.internet2.middleware.grouperClient.encryption.GcGenerateKey 
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.encryptionKey$"}
#changeLog.consumer.awsJira.encryptionKey = abc123

# if you dont want to send the first 4 of the sha hash base 64 of the secret
# {valueType: "boolean", regex: "^changeLog\\.consumer\\.([^.]+)\\.dontSendShaBase64secretFirst4$"}
#changeLog.consumer.awsJira.dontSendShaBase64secretFirst4 = false

# publisher class
# {valueType: "class", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.class$", mustExtendClass: "edu.internet2.middleware.grouperAwsChangelog.GrouperAwsEsbPublisher"}
#changeLog.consumer.awsJira.publisher.class = edu.internet2.middleware.grouperAwsChangelog.GrouperAwsEsbPublisher

# aws access key
# {valueType: "password", sensitive: true, regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.awsAccessKey$"}
#changeLog.consumer.awsJira.publisher.awsAccessKey = ABCXYZ

# aws secret key
# {valueType: "password", sensitive: true, regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.awsSecretKey$"}
#changeLog.consumer.awsJira.publisher.awsSecretKey = 123REWQ

# aws region
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.awsRegion$"}
#changeLog.consumer.awsJira.publisher.awsRegion = US_EAST_1

# aws sns topic arn
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.awsSnsTopicArn$"}
#changeLog.consumer.awsJira.publisher.awsSnsTopicArn = arn:aws:sns:us-east-1:123:name

# quartz cron
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.quartzCron$"}
#changeLog.consumer.xmppTest.quartzCron = 

# class
# {valueType: "class", required: true, mustExtendClass: "edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbConsumer", regex: "^changeLog\\.consumer\\.([^.]+)\\.class$"}
#changeLog.consumer.xmppTest.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbConsumer

# el filter
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.elfilter$"}
#changeLog.consumer.xmppTest.elfilter = event.eventType eq 'GROUP_DELETE' || event.eventType eq 'GROUP_ADD' || event.eventType eq 'MEMBERSHIP_DELETE' || event.eventType eq 'MEMBERSHIP_ADD'

# publisher class
# {valueType: "class", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.class$", mustExtendClass: "edu.internet2.middleware.grouperAwsChangelog.GrouperAwsEsbPublisher"}
#changeLog.consumer.xmppTest.publisher.class = edu.internet2.middleware.grouper.changeLog.esb.consumer.EsbXmppPublisher

# publisher server
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.server$"}
#changeLog.consumer.xmppTest.publisher.server = jabber.school.edu

# {valueType: "integer", required: true, regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.port$"}
#changeLog.consumer.xmppTest.publisher.port = 5222

# user name
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.username$"}
#changeLog.consumer.xmppTest.publisher.username = jabberuser

# password
# {valueType: "password", sensitive: true, regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.password$"}
#changeLog.consumer.xmppTest.publisher.password = /home/whatever/pass/jabberuserEncrypted.pass

# recipient
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.recipient$"}
#changeLog.consumer.xmppTest.publisher.recipient = system1@school.edu

# add subject attributes
# {valueType: "string", multiple: true, regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.addSubjectAttributes$"}
#changeLog.consumer.xmppTest.publisher.addSubjectAttributes = NETID

#note, on the content type header, activemq might need: application/x-www-form-urlencoded
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.contentTypeHeader$"}
#changeLog.consumer.xmppTest.publisher.contentTypeHeader = application/json; charset=utf-8

#note, on the stringRequestEntityPrefix, activemq might need: data=
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.stringRequestEntityPrefix$"}
#changeLog.consumer.xmppTest.publisher.stringRequestEntityPrefix = 

#note, on the stringRequestEntityContentType, activemq might need: application/x-www-form-urlencoded
# {valueType: "string", regex: "^changeLog\\.consumer\\.([^.]+)\\.publisher\\.stringRequestEntityContentType$"}
#changeLog.consumer.xmppTest.publisher.stringRequestEntityContentType = application/json


################################
## Other jobs built-in
## 
## Configure other jobs.
## "jobName" is the name of your job.
## Class must implement org.quartz.Job.
## Priority is optional
##
## For jobs that run by default, you can disable them by setting an empty quartz cron in grouper-loader.properties.
################################

# Find and fix bad memberships class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.findBadMemberships.class = edu.internet2.middleware.grouper.misc.FindBadMembershipsDaemon

# Find and fix bad memberships cron
# {valueType: "string"}
otherJob.findBadMemberships.quartzCron = 0 0 1 * * ?

# Find and fix scheduler issues class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.schedulerCheckDaemon.class = edu.internet2.middleware.grouper.app.loader.GrouperDaemonSchedulerCheck

# Find and fix scheduler issues cron
# {valueType: "string"}
otherJob.schedulerCheckDaemon.quartzCron = 25 0/30 * * * ?

# Atttestation Job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.attestationDaemon.class = edu.internet2.middleware.grouper.app.attestation.GrouperAttestationJob

# Atttestation Job cron
# {valueType: "string"}
otherJob.attestationDaemon.quartzCron = 0 0 1 * * ?

# Deprovisioning Job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.deprovisioningDaemon.class = edu.internet2.middleware.grouper.app.deprovisioning.GrouperDeprovisioningJob

# Deprovisioning Job cron
# {valueType: "string"}
otherJob.deprovisioningDaemon.quartzCron = 0 0 2 * * ?

# Object Type Job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.grouperObjectTypeDaemon.class = edu.internet2.middleware.grouper.app.grouperTypes.GrouperObjectTypesJob

# Object Type Job cron
# {valueType: "string"}
otherJob.grouperObjectTypeDaemon.quartzCron = 0 0 3 * * ?

# Provisioning Job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.grouperProvisioningDaemon.class = edu.internet2.middleware.grouper.app.provisioning.GrouperProvisioningJob

# Provisioning Job cron
# {valueType: "string"}
otherJob.grouperProvisioningDaemon.quartzCron = 0 0 4 * * ?

# Run upgrade tasks
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.upgradeTasks.class = edu.internet2.middleware.grouper.app.upgradeTasks.UpgradeTasksJob

# Run upgrade tasks cron
# {valueType: "string"}
otherJob.upgradeTasks.quartzCron = 5 25 * * * ?

# reports clear Job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.grouperReportClearDaemon.class = edu.internet2.middleware.grouper.app.reports.GrouperReportClearJob

# reports clear Job cron
# {valueType: "string"}
otherJob.grouperReportClearDaemon.quartzCron = 0 0 3 * * ?

# Workflow daemon that updates instances and send emails
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.grouperWorkfowDaemon.class = edu.internet2.middleware.grouper.app.workflow.GrouperWorkflowDaemonJob

# Object Type Job cron
# {valueType: "string"}
otherJob.grouperWorkfowDaemon.quartzCron = 0 0/5 * ? * * *

# Workflow reminder email daemon
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.grouperWorkfowReminderDaemon.class = edu.internet2.middleware.grouper.app.workflow.GrouperWorkflowReminderEmailJob

# Object Type Job cron
# {valueType: "string"}
otherJob.grouperWorkfowReminderDaemon.quartzCron = 0 0 4 * * ? 

################################
## Table sync jobs
## tableSync jobs should use class: edu.internet2.middleware.grouper.app.tableSync.TableSyncOtherJob
## and include a setting to point to the grouperClient config, if not same: otherJob.<otherJobName>.grouperClientTableSyncConfigKey = key
## this is the subtype of job to run: otherJob.<otherJobName>.syncType = fullSyncFull    
## (can be: fullSyncFull, fullSyncGroupings, fullSyncChangeFlag, incrementalAllColumns, incrementalPrimaryKey)
################################

# Object Type Job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
# otherJob.membershipSync.class = edu.internet2.middleware.grouper.app.tableSync.TableSyncOtherJob

# Object Type Job cron
# {valueType: "string"}
# otherJob.membershipSync.quartzCron = 0 0/30 * * * ?

# this is the key in the grouper.client.properties that represents this job
# {valueType: "string"}
# otherJob.membershipSync.grouperClientTableSyncConfigKey = memberships

# fullSyncFull, fullSyncGroupings, fullSyncChangeFlag, incrementalAllColumns, incrementalPrimaryKey
# {valueType: "string"}
# otherJob.membershipSync.syncType = fullSyncFull

# USDU Job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
otherJob.usduDaemon.class = edu.internet2.middleware.grouper.app.usdu.UsduJob

# USDU Job cron
# {valueType: "string"}
otherJob.usduDaemon.quartzCron = 0 0 1 ? * SAT *

################################
## Other jobs
## 
## Configure other jobs.
## "jobName" is the name of your job.
## Class must implement org.quartz.Job.  Should extend edu.internet2.middleware.grouper.app.loader.OtherJobBase
## Priority is optional
## see edu.internet2.middleware.grouper.app.loader.GrouperLoaderIncrementalJob as an example
##
################################

# other job class
# {valueType: "class", regex: "^otherJob.([^.]+).class$", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
# otherJob.jobName.class = 

# other job quartz cron
# {valueType: "string", regex: "^otherJob.([^.]+).quartzCron$"}
# otherJob.jobName.quartzCron = 

# other job priority (optional)
# {valueType: "integer", regex: "^otherJob.([^.]+).priority$"}
# otherJob.jobName.priority =


#####################################
## Object Type Job
#####################################
otherJob.grouperObjectTypeDaemon.class = edu.internet2.middleware.grouper.app.grouperTypes.GrouperObjectTypesJob
otherJob.grouperObjectTypeDaemon.quartzCron = 0 0 3 * * ?


#####################################
## Message to WS Daemon Job
#####################################

# message to ws daemon job class
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase", mustImplementInterface: "org.quartz.Job"}
#otherJob.messageConsumerDaemon.class = edu.internet2.middleware.grouper.app.messaging.MessageConsumerDaemon

# message to ws daemon job cron
# {valueType: "string"}
#otherJob.messageConsumerDaemon.quartzCron = 0 * * ? * *

# there can be multiple entries, "wsMessagingBridge" is the name of this one, change that for each config section
# the messaging system name must correspond to a messaging system in the grouper.client.properties
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.messagingSystemName$"}
# grouper.messaging.wsMessagingBridge.messagingSystemName = rabbitMqMessaging

# the queue or topic to check
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.messagingSystemName$"}
#grouper.messaging.wsMessagingBridge.queueOrTopicName = sampleWsMessagingQueue

# routingKey is only valid for rabbitmq; for others, it's ignored
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.routingKey$"}
#grouper.messaging.wsMessagingBridge.routingKey = 

# exchangeType is only valid for rabbitmq; for others, it's ignored. Valid options are DIRECT, TOPIC, HEADERS, FANOUT
# {valueType: "string", required: false, regex: "^grouper\\.messaging\\.([^.]+)\\.exchangeType$"}
#grouper.messaging.wsMessagingBridge.exchangeType = 

# if this is a "queue" or "topic", generally it will be queue
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.messageQueueType$"}
#grouper.messaging.wsMessagingBridge.messageQueueType = queue

# the source id of the source of the user to act as
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.actAsSubjectSourceId$"}
#grouper.messaging.wsMessagingBridge.actAsSubjectSourceId = g:isa

# the subject id of the user to act as
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.actAsSubjectId$"}
#grouper.messaging.wsMessagingBridge.actAsSubjectId = GrouperSystem
 
# the long polling seconds, listen to the queue for this many seconds for messages
# {valueType: "integer", required: true, regex: "^grouper\\.messaging\\.([^.]+)\\.longPollingSeconds$"}
#grouper.messaging.wsMessagingBridge.longPollingSeconds = 20

# grouper ws url
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.ws\\.url$"}
#grouper.messaging.wsMessagingBridge.ws.url =

# grouper ws username
# {valueType: "string", regex: "^grouper\\.messaging\\.([^.]+)\\.ws\\.username$"}
#grouper.messaging.wsMessagingBridge.ws.username = 

# grouper ws password
# {valueType: "password", sensitive: true, regex: "^grouper\\.messaging\\.([^.]+)\\.ws\\.password$"}
#grouper.messaging.wsMessagingBridge.ws.password = 

#####################################################
## TIER Instrumentation daemon - send stats to TIER.
#####################################################

# set this to enable the instrumentation
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase"}
otherJob.tierInstrumentationDaemon.class = edu.internet2.middleware.grouper.instrumentation.TierInstrumentationDaemon

# cron string
# {valueType: "string"}
otherJob.tierInstrumentationDaemon.quartzCron = 0 0 2 * * ?

# collector url
# {valueType: "string"}
otherJob.tierInstrumentationDaemon.collectorUrl = http://collector.testbed.tier.internet2.edu:5001

#####################################################
## CSV reports
## "reportId" is the key of the config, change that for your csv report
#####################################################


# set this to enable the instrumentation
# {valueType: "class", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.OtherJobBase"}
# otherJob.reportId.class = edu.internet2.middleware.grouper.app.reports.GrouperCsvReportJob

# cron string
# {valueType: "string"}
# otherJob.reportId.quartzCron = 0 21 7 * * ?

# query to run
# {valueType: "string", regex: "^otherJob\\.([^.]+)\\.csvReport\\.query$"}
# otherJob.reportId.csvReport.query = select USER_ID, USER_NAME, EMAIL_ADDRESS, AUTH_TYPE, TITLE, DEPARTMENT, CUSTOM_STRING, DAY_PASS, CUSTOM_STRING2, GROUPS from some_view

# database to hit
# {valueType: "string", regex: "^otherJob\\.([^.]+)\\.csvReport\\.database$"}
# otherJob.reportId.csvReport.database = pennCommunity

# remove underscores and capitalize headers, go from USER_NAME to UserName
# {valueType: "string", regex: "^otherJob\\.([^.]+)\\.csvReport\\.removeUnderscoresAndCapitalizeHeaders$"}
# otherJob.reportId.csvReport.removeUnderscoresAndCapitalizeHeaders = false

# fileName, e.g. myFile.csv or /opt/whatever/myFile.csv.  If blank will create a name 
# {valueType: "string", regex: "^otherJob\\.([^.]+)\\.csvReport\\.database$"}
# otherJob.reportId.csvReport.fileName = MyFile.csv

# sftp config id (from grouper.properties) if sftp'ing this file somewhere, otherwise blank
# https://spaces.at.internet2.edu/display/Grouper/Grouper+Sftp+files
# {valueType: "string", regex: "^otherJob\\.([^.]+)\\.csvReport\\.sftp\\.configId$"}
# otherJob.reportId.csvReport.sftp.configId = someSftpServer

# remote file to sftp to if sftp'ing
# {valueType: "string", regex: "^otherJob\\.([^.]+)\\.csvReport\\.sftp\\.fileNameRemote$"}
# otherJob.reportId.csvReport.sftp.fileNameRemote = /data01/whatever/MyFile.csv

# if the file should be deleted from the grouper daemon server after sending it
# {valueType: "boolean", regex: "^otherJob\\.([^.]+)\\.csvReport\\.deleteFile$"}
# otherJob.reportId.csvReport.deleteFile = true



############################
## Incremental loader jobs
############################

# incremental loader job class
# {valueType: "class", regex: "^otherJob.([^.]+).class$", mustExtendClass: "edu.internet2.middleware.grouper.app.loader.GrouperLoaderIncrementalJob"}
# otherJob.incrementalLoader1.class = edu.internet2.middleware.grouper.app.loader.GrouperLoaderIncrementalJob

# incremental loader job cron
# {valueType: "string", regex: "^otherJob.([^.]+).quartzCron$"}
# otherJob.incrementalLoader1.quartzCron = 0 * * * * ?

# incremental loader job database name
# {valueType: "string", regex: "^otherJob.([^.]+).databaseName$"}
# otherJob.incrementalLoader1.databaseName=warehouse

# incremental loader job table name
# {valueType: "string", regex: "^otherJob.([^.]+).tableName$"}
# otherJob.incrementalLoader1.tableName=myincrementaltable

# incremental loader full sync threshold
# If there are more than this many changes for a single loader job, then invoke the full sync instead.  This could improve performance but also handle fail safe which isn't part of the incremental sync.
# {valueType: "integer", regex: "^otherJob.([^.]+).fullSyncThreshold$"}
# otherJob.incrementalLoader1.fullSyncThreshold=100

# whether subject lookups in the data source should be case insensitive.  only applicable for sql loader jobs.  note, if true, for some databases (e.g. oracle), you may need a function based index in your data source for the function "lower" for better performance
# {valueType: "boolean", regex: "^otherJob.([^.]+).caseInsensitiveSubjectLookupsInDataSource$"}
# otherJob.incrementalLoader1.caseInsensitiveSubjectLookupsInDataSource=false


#############
## Quartz settings
#############

# quartz schedule instance name
# {valueType: "string", required: true}
org.quartz.scheduler.instanceName = DefaultQuartzScheduler

# quartz scheduler instnace id
# {valueType: "string", required: true}
org.quartz.scheduler.instanceId = AUTO

# quartz scheduler rmi export
# {valueType: "boolean", required: true}
org.quartz.scheduler.rmi.export = false

# quartz scheduler rmi proxy
# {valueType: "boolean", required: true}
org.quartz.scheduler.rmi.proxy = false

# quartz scheduler wrap job executiong transaction
# {valueType: "boolean", required: true}
org.quartz.scheduler.wrapJobExecutionInUserTransaction = false

# quartz scheduler thread pool class
# {valueType: "class", required: true, mustImplementInterface: "org.quartz.spi.ThreadPool"}
org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool

# quartz scheduler thread count
# {valueType: "integer", required: true}
org.quartz.threadPool.threadCount = 10

# quartz scheduler thread priority
# {valueType: "integer", required: true}
org.quartz.threadPool.threadPriority = 5

# quartz scheduler threads inherit context class
# {valueType: "boolean", required: true}
org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = true

# quartz scheduler misfire threshold
# {valueType: "integer", required: true}
org.quartz.jobStore.misfireThreshold = 60000

# quartz scheduler jobstore class
# {valueType: "class", required: true, mustImplementInterface: "org.quartz.spi.JobStore"}
org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX

# quartz scheduler data source
# {valueType: "string"}
org.quartz.jobStore.dataSource = myDS

# quartz scheduler table prefix
# {valueType: "string"}
org.quartz.jobStore.tablePrefix = grouper_QZ_

# quartz scheduler is clustered
# {valueType: "boolean", required: true}
org.quartz.jobStore.isClustered = true

# quartz scheduler check in interval
# {valueType: "integer", required: true}
org.quartz.jobStore.clusterCheckinInterval = 20000

# quartz scheduler max connections
# {valueType: "integer", required: true}
org.quartz.dataSource.myDS.maxConnections = 5

# quartz scheduler validation query
# {valueType: "string"}
org.quartz.dataSource.myDS.validationQuery = select id from grouper_ddl

# automatically determined but can override
# {valueType: "class"}
org.quartz.jobStore.driverDelegateClass =

# automatically determined based on hibernate configuration but can override
# {valueType: "class"}
org.quartz.dataSource.myDS.driver =

# quartz scheduler my ds url
# {valueType: "string"}
org.quartz.dataSource.myDS.URL =

# quartz scheduler my ds user
# {valueType: "string"}
org.quartz.dataSource.myDS.user =

# quartz scheduler my ds pass
# {valueType: "password", sensitive: true}
org.quartz.dataSource.myDS.password =


# Quartz seems to have issues where sometimes a job is running twice at the same time, usually after a misfire.
# We have our own check to make sure jobs don't overlap based on data in the grouper_loader_log table if a job's status is STARTED.
# However, if the daemon is killed, it may be stuck on the STARTED state until the row is deleted.  So we'll consider a job's
# STARTED state to be invalid if it hasn't been updated in the number of seconds below.
# {valueType: "integer", required: true}
loader.assumeJobKilledIfNoUpdateInSeconds=300

#############
## Provisioning and sync settings
#############

# delete metadata information about things not provisioned anymore and removed from target (default 1 week)
# {valueType: "integer"}
grouper.provisioning.removeSyncRowsAfterSecondsOutOfTarget = 604800


#############
## Grouper Duo provisioning
#############


# group duo admin domain name credentials
# {valueType: "string"}
# grouperDuo.adminIntegrationKey = 

# group duo admin domain name secret
# {valueType: "password"}
# grouperDuo.adminSecretKey = 

# group duo admin domain name credentials
# {valueType: "string"}
# grouperDuo.adminDomainName = 

# use ui provisioning configuration, not config file
# {valueType: "boolean"}
grouperDuo.use.ui.provisioning.configuration = true

# use ui provisioning configuration, not config file
# {valueType: "string"}
# grouperDuo.ui.provisioning.targetName = duoProd

# put groups in here which go to duo, the name in duo will be the extension here
# this ust be blank if using UI provisioning configuration
# {valueType: "stem"}
# grouperDuo.folder.name.withDuoGroups = 

# put the comma separated list of sources to send to duo
# {valueType: "string"}
# grouperDuo.sourcesForSubjects = someSource

# either have id for subject id or an attribute for the duo username (e.g. netId)
# {valueType: "string"}
# grouperDuo.subjectAttributeForDuoUsername = id

# is grouper the true system of record, delete duo groups which dont exist in grouper
# {valueType: "boolean"}
# grouperDuo.deleteGroupsInDuoWhichArentInGrouper = true

# configure the duo change log consumer
# {valueType: "class"}
# changeLog.consumer.duo.class = edu.internet2.middleware.grouperDuo.GrouperDuoChangeLogConsumer

#the quartz cron is a cron-like string.  it defaults to every minute on the minute (since the temp to change log job runs
#at 10 seconds to each minute).  it defaults to this: 0 * * * * ?
#though it will stagger each one by 2 seconds
# http://www.quartz-scheduler.org/documentation/quartz-1.x/tutorials/crontrigger
# {valueType: "string"}
# changeLog.consumer.duo.quartzCron = 

# Schedule full refresh
# {valueType: "class"}
# otherJob.duo.class = edu.internet2.middleware.grouperDuo.GrouperDuoFullRefresh

# Quartz cron
# {valueType: "string"}
# otherJob.duo.quartzCron = 0 0 5 * * ?

# The folder in which duo administrator groups will be located
# {valueType: "string"}
# grouperDuo.folder.name.withDuoAdmins =

# The attribute to assign to the user with their administrator id.
# {valueType: "string"}
# grouperDuo.attributeForAdminId =

# The attribute assigned to the group containing the group's role
# {valueType: "string"}
# grouperDuo.attributeForAdminRole =

# The subject attribute for the name provided to Duo for new Administrator accounts
# {valueType: "string"}
# grouperDuo.subjectAttributeForName = name

# The subject attribute for the fallback number to be provided to Duo for new Administrator accounts.
# This value is only used if the user does not already have a phone number on a regular Duo account. 
# If one exists, the primary phone on the user's regular Duo account will be used first.
# {valueType: "string"}
# grouperDuo.subjectAttributeForPhoneName = phone

# The subject attribute for the user's email address.
# {valueType: "string"}
# grouperDuo.subjectAttributeForEmailName = email

# If true, grouper will manage Duo administrators. Disabled by default. 
# Your Duo application keys will require permissions to manage administrators.
# {valueType: "boolean"}
# grouperDuo.adminSyncEnabled = false

# A comma separated set of Duo roles to be managed. By default it includes all roles.
# {valueType: "string", multiple: true}
# grouperDuo.manageableAdminRoles = Owner,Administrator,Application Manager,User Manager,Help Desk,Billing,Phishing Manager,Read-only

# The default password to assign to created administrator accounts. Must meet Duo's administrator password policies.
# {valueType: "password"}
# grouperDuo.defaultAdminPassword = 

# If true, administrator accounts that are not managed by Grouper will be disabled.
# {valueType: "boolean"}
# grouperDuo.disableUnknownAdmins = false

# If true, disabled administrator accounts that are not managed by Grouper will be deleted.
# Only disabled administrator accounts will be deleted, so grouperDuo.disableUnknownAdmins should
# be set to true.
# {valueType: "boolean"}
# grouperDuo.deleteUnknownAdmins = false

# If grouperDuo.deleteUnkownAdmins is true, it will wait this many seconds since the user's last login
# before deleting the account. This is helpful when a user is switching roles, they do not have to 
# register their device again.
# {valueType: "boolean"}
# grouperDuo.deleteUnknownAdminsAfterSeconds = 2592000

# Comma separated list of email addresses to ignore when managing Administrators.
# {valueType: "boolean"}
# grouerDuo.ignoreAdminEmails = 

